<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>The Gentle Singularity - Sam Altman</title>
</head>
<body>
        <h1>The Gentle Singularity - Sam Altman</h1>
  
  <div><a href="https://blog.samaltman.com/the-gentle-singularity">The Gentle Singularity-  blog.samaltman.com</a></div><div><br></div><div>I have never been as alarmed like everyone else about AI taking over the world until I read this post. It's not the AI I am worried about. But the human intentions behind the machines. </div><div><br></div><blockquote>There are other self-reinforcing loops at play. The economic value creation has started a flywheel of compounding infrastructure buildout to run these increasingly-powerful AI systems. And robots that can build other robots (and in some sense, datacenters that can build other datacenters) aren’t that far off. <br><br>If we have to make the first million humanoid robots the old-fashioned way, but then they can operate the entire supply chain—digging and refining minerals, driving trucks, running factories, etc.—to build more robots, which can build more chip fabrication facilities, data centers, etc, then the rate of progress will obviously be quite different.</blockquote><div>
<br><br><br>“Singularity” = a tipping / transformation point where intelligence + energy + automation become abundant and the fundamental limits on human progress shift.</div>
</body>
</html>